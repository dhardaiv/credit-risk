# -*- coding: utf-8 -*-
"""CreditRiskAssesment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1E88f1VnGjUmeuJR0JqKBEm1dQBK9QXVa
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

df = pd.read_csv('credit_risk_dataset.csv')
df

df.head()

df.tail()

#begin data cleaning

df.shape

print(f'rows: {df.shape[0]}')
print(f'cols: {df.shape[1]}')
df.info()

#checking null values
df.isnull().sum()

#unique values in each col
df.nunique()

#dropping the NaN values
df.dropna(axis=0,inplace=True)

df.isnull().sum()

df.duplicated().sum()

df.drop_duplicates(inplace=True)

df.shape

#identifying outliers

df.dtypes

num_cols= df.select_dtypes(include=['int64', 'float64'])
num_cols

df.dropna(axis=0,inplace=True)

df.isnull().sum()

df.shape

outlier_age= df[df["person_age"] > 80].shape[0]
outlier_age

df = df[df["person_age"] < 80]
df.shape

outliers_emp_length = df[df['person_emp_length'] > 80].shape[0]
outliers_emp_length

df = df[df['person_emp_length'] <= 80]
df.describe()

df.shape

sns.histplot(data= df, x='person_age')
plt.show()

"""We can see that count drastically decreases when age>60. so, removing count for age>80 was a good choice. Now, we can begin building our model - first beginning with splitting the training and test data."""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
numerical_cols = ['person_age', 'person_income', 'person_emp_length', 'loan_amnt', 'loan_int_rate', 'loan_percent_income', 'cb_person_cred_hist_length']
df[numerical_cols] = scaler.fit_transform(df[numerical_cols])

df[numerical_cols]

df

X = df.drop('loan_status', axis=1)
y = df['loan_status']

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

models = {
    'XGBoost': XGBClassifier(),
}

model_results = {}
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else y_pred

    model_results[name] = {
        'Accuracy': accuracy_score(y_test, y_pred),
        'Precision': precision_score(y_test, y_pred),
        'Recall': recall_score(y_test, y_pred),
        'F1 Score': f1_score(y_test, y_pred),
        'ROC AUC': roc_auc_score(y_test, y_pred_proba)
    }

# Convert results to DataFrame
results_df = pd.DataFrame(model_results).T
print(results_df)